{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96befb26",
   "metadata": {},
   "source": [
    "# Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9884c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call functions\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# load model and data\n",
    "from model_ingestion.data_model import load_data_model\n",
    "\n",
    "# Local Explanation\n",
    "from local_exp.local_exp import dalex_exp\n",
    "\n",
    "# ExplainerDashboard\n",
    "from explainerdashboard import *\n",
    "from eda.dashboard import *\n",
    "from fairness.dashboard import *\n",
    "from local_exp.dashboard import *\n",
    "from global_exp.dashboard import *\n",
    "from stability.dashboard import *\n",
    "from robustness.dashboard import *\n",
    "from uncertainty.dashboard import *\n",
    "\n",
    "from raiwidgets.responsibleai_dashboard import ResponsibleAIDashboard\n",
    "from fairness.XRAI_features import *\n",
    "from raiwidgets import ErrorAnalysisDashboard\n",
    "\n",
    "# AutoEDA\n",
    "import dtale.app as dtale_app\n",
    "from contextlib import redirect_stdout\n",
    "\n",
    "# Dash\n",
    "import dash_bootstrap_components as dbc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e57562",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82871822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required datasets and model -- regression example. Comment out if using classification use case\n",
    "\n",
    "train_data = 'data/property_valuation/train_property_valuation.csv' ## INPUT HERE\n",
    "test_data = 'data/property_valuation/test_property_valuation.csv' ## INPUT HERE\n",
    "model_path = {\"LGBM\":'models/property_valuation/property_valuation_lgbm.sav',\"DT\":'models/property_valuation/property_valuation_decision_tree.sav'} ## INPUT HERE\n",
    "target_feature = 'price_sqm' ## INPUT HERE\n",
    "\n",
    "X_train, y_train, X_test, y_test, train_data, test_data, model = load_data_model(train_data, test_data, model_path, target_feature)\n",
    "\n",
    "cont = X_train.select_dtypes(include = np.number).columns.tolist()\n",
    "cat = X_train.select_dtypes(exclude = np.number).columns.tolist()\n",
    "\n",
    "reg = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d44edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load required datasets and model -- classification example. Comment out if using regression use case\n",
    "\n",
    "# import sklearn\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.impute import SimpleImputer, KNNImputer\n",
    "# from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from xgboost import XGBClassifier\n",
    "\n",
    "# X_train = pd.read_csv(f'data/loans/loans_X_train.csv', index_col = 0)\n",
    "# X_test = pd.read_csv(f'data/loans/loans_X_test.csv', index_col = 0)\n",
    "# y_train = pd.read_csv(f'data/loans/loans_y_train.csv', index_col = 0).squeeze()\n",
    "# y_test = pd.read_csv(f'data/loans/loans_y_test.csv', index_col = 0).squeeze()\n",
    "\n",
    "# train_data = pd.concat([X_train, y_train], axis = 1)\n",
    "# test_data = pd.concat([X_test, y_test], axis = 1)\n",
    "\n",
    "# target = ['loan_status']\n",
    "\n",
    "# drop_cols = ['id', 'member_id', 'issue_d', 'title', 'zip_code', 'addr_state', 'last_pymnt_d',\n",
    "#              'next_pymnt_d', 'last_credit_pull_d', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim']\n",
    "\n",
    "# # ord_cols = [#'grade', 'sub_grade', \n",
    "# #             'earliest_cr_line', 'emp_length']\n",
    "\n",
    "# num_cols = list(set(train_data.select_dtypes(include = ['int64', 'float64']).columns.tolist()) - set(drop_cols) - set(target))\n",
    "# cat_cols = list(set(train_data.select_dtypes(exclude = ['int64', 'float64']).columns.tolist()) - set(drop_cols) - set(target))\n",
    "\n",
    "# rem_cols = list(set(train_data.columns.tolist()) - set(num_cols) - set(cat_cols) - set(drop_cols) - set(target))\n",
    "\n",
    "# print('Numerical Columns:\\n', num_cols)\n",
    "# print('\\nCategorical Columns:\\n', cat_cols)\n",
    "# print('\\nRemaining Columns:\\n', rem_cols)\n",
    "\n",
    "# cont = X_train.select_dtypes(include = np.number).columns.tolist()\n",
    "# cat = X_train.select_dtypes(exclude = np.number).columns.tolist()\n",
    "\n",
    "# seed = 42\n",
    "\n",
    "# numerical = Pipeline(\n",
    "#     steps = [\n",
    "#         ('num_imputer', KNNImputer()),\n",
    "#         ('scaler', StandardScaler())\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# categorical = Pipeline(\n",
    "#     steps = [\n",
    "#         ('cat_imputer', SimpleImputer(strategy = 'constant', fill_value = 'No Data')),\n",
    "#         ('ohe', OneHotEncoder(handle_unknown = 'ignore'))\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# preproc = ColumnTransformer([\n",
    "#     ('num', numerical, num_cols),\n",
    "#     ('cat', categorical, cat_cols),\n",
    "#     ('drop', 'drop', drop_cols),\n",
    "# ])\n",
    "\n",
    "# # Decision Tree\n",
    "# pipe = Pipeline(\n",
    "#     steps = [\n",
    "#         ('preproc', preproc),\n",
    "#         ('clr', DecisionTreeClassifier(random_state = seed, criterion = 'gini',\n",
    "#                                       max_depth = 22, max_features = .75))\n",
    "#     ]\n",
    "# )\n",
    "# pipe.fit(X_train, y_train)\n",
    "# model_dt = pipe\n",
    "\n",
    "# # Random Forest\n",
    "# pipe = Pipeline(\n",
    "#     steps = [\n",
    "#         ('preproc', preproc),\n",
    "#         ('clf', RandomForestClassifier(random_state = seed, criterion = 'gini',\n",
    "#                                       max_depth = None, max_features = 'log2',\n",
    "#                                       n_estimators = 250))\n",
    "#     ]\n",
    "# )\n",
    "# pipe.fit(X_train, y_train)\n",
    "# model_rf = pipe\n",
    "\n",
    "# # XGBoost\n",
    "# pipe = Pipeline(\n",
    "#     steps = [\n",
    "#         ('preproc', preproc),\n",
    "#         ('clf', XGBClassifier(max_depth = 25, n_estimators = 250, random_state = seed))\n",
    "#     ]\n",
    "# )\n",
    "# pipe.fit(X_train, y_train)\n",
    "# model_xgb = pipe\n",
    "\n",
    "# model = {'DT': model_dt,\n",
    "#          'RF': model_rf,\n",
    "#          'XGB': model_xgb}\n",
    "\n",
    "# preprocessor = model['DT'][0]\n",
    "# preprocessor2 = model['RF'][0]\n",
    "# preprocessor3 = model['XGB'][0]\n",
    "\n",
    "# reg = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec29bf",
   "metadata": {},
   "source": [
    "# Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982c873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and explainer for the dashboard\n",
    "try:\n",
    "    explainer = ClassifierExplainer(model['DT'], X_test, y_test) # Input the test set and classifier model here\n",
    "except:\n",
    "    explainer = RegressionExplainer(model['DT'], X_test, y_test) # Input the test set and regression model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b14a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure your sklearn pipeline here\n",
    "pipe = Pipeline(\n",
    "    steps = [\n",
    "        ('step1', model['DT'][0]),\n",
    "        ('step2', model['DT'][1])\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322c41c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the groupings for the Grouped Variable Importances Component in the Dashboard. Set to None for no groupings\n",
    "if reg:\n",
    "    variable_groups = {\n",
    "        'cmci': ['infrastructure', 'resiliency', 'productivity', 'security', 'transparency', 'utilities'],\n",
    "        'house_amenities': [ 'ac_unit', 'balcony', 'deck', 'fence', 'fireplace', 'fitness_center', 'garage',\n",
    "                            'grass', 'library_books', 'local_airport', 'local_parking', 'meeting_room', 'park',\n",
    "                            'pool', 'security.1', 'smoke_free', 'sports_basketball', 'sports_tennis',\n",
    "                            'sports_volleyball', 'warehouse', 'yard'],\n",
    "        'house_characteristics': ['price_conditions', 'car_spaces', 'bedrooms', 'bathrooms', 'floor_area', 'land_size'],\n",
    "        'LOI_1000': ['cafe_1000', 'fast_food_1000', 'pub_1000', 'restaurant_1000', 'college_1000', 'kindergarten_1000',\n",
    "                    'school_1000', 'university_1000', 'fuel_1000', 'parking_1000', 'atm_1000', 'bank_1000', 'clinic_1000',\n",
    "                    'hospital_1000', 'pharmacy_1000', 'police_1000', 'townhall_1000', 'marketplace_1000', 'hotel_1000',\n",
    "                    'residential_1000', 'commercial_1000', 'industrial_1000', 'retail_1000', 'supermarket_1000',\n",
    "                    'fire_station_1000', 'government_1000'],\n",
    "        'LOI_3000': ['cafe_3000', 'fast_food_3000', 'pub_3000', 'restaurant_3000', 'college_3000', 'kindergarten_3000',\n",
    "                    'school_3000', 'university_3000', 'fuel_3000', 'parking_3000', 'atm_3000', 'bank_3000', 'clinic_3000',\n",
    "                    'hospital_3000', 'pharmacy_3000', 'police_3000', 'townhall_3000', 'marketplace_3000', 'hotel_3000',\n",
    "                    'residential_3000', 'commercial_3000', 'industrial_3000', 'retail_3000', 'supermarket_3000',\n",
    "                    'fire_station_3000', 'government_3000'],\n",
    "        'LOI_5000': ['cafe_5000', 'fast_food_5000', 'pub_5000', 'restaurant_5000', 'college_5000', 'kindergarten_5000',\n",
    "                    'school_5000', 'university_5000', 'fuel_5000', 'parking_5000', 'atm_5000', 'bank_5000', 'clinic_5000',\n",
    "                    'hospital_5000', 'pharmacy_5000', 'police_5000', 'townhall_5000', 'marketplace_5000', 'hotel_5000',\n",
    "                    'residential_5000', 'commercial_5000', 'industrial_5000', 'retail_5000', 'supermarket_5000',\n",
    "                    'fire_station_5000', 'government_5000'],\n",
    "        'socio-economic': ['LGU', 'poverty_inc', 'subs_inc', 'lgu_type', 'income_class', 'anreg_income_2021',\n",
    "                        'capex_2021', 'socex_2021', 'pop_2022', 'growth_5years', 'growth_10years']\n",
    "    }\n",
    "elif not reg:\n",
    "    variable_groups = {\n",
    "        'total': ['total_acc', 'total_pymnt', 'total_pymnt_inv', 'total_rec_prncp',\n",
    "                    'total_rec_int', 'total_rec_late_fee', 'total_rev_hi_lim'],\n",
    "            'amount': ['loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'last_pymnt_amnt'],\n",
    "            'categorical': X_train.select_dtypes(exclude = ['int64', 'float64']).columns.tolist()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225baf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate continuous and categorical variables\n",
    "cont = X_train.select_dtypes(include = ['int64', 'float64']).columns.tolist()\n",
    "cat = X_train.select_dtypes(exclude = ['int64', 'float64']).columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9947e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only one model should be selected, and it should be in a dictionary form\n",
    "model_selected = {'DT': model['DT']}\n",
    "if reg:\n",
    "    model_type = 'regressor'\n",
    "elif not reg:\n",
    "    model_type = 'classifier'\n",
    "is_sklearn_pipe = True # Did it use sklearn pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710d2cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Dalex explainer for the global explanation components\n",
    "exp, obs = dalex_exp(list(model_selected.values())[0], X_train, y_train, X_test, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d6c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.concat([train_data, test_data], axis=0)\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb58ac4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reg:\n",
    "    features = pipe.get_feature_names_out()\n",
    "    pipe.fit(X_train)\n",
    "    X_train_proc = pd.DataFrame(pipe.transform(X_train), columns=features)\n",
    "    X_test_proc = pd.DataFrame(pipe.transform(X_test), columns=features)\n",
    "elif not reg:\n",
    "    features = preprocessor.get_feature_names_out()\n",
    "    preprocessor.fit(X_train)\n",
    "    X_train_proc = pd.DataFrame(preprocessor.transform(X_train), columns=features)\n",
    "    X_test_proc = pd.DataFrame(preprocessor.transform(X_test), columns=features)\n",
    "train_data_proc = pd.concat([X_train_proc, y_train], axis=1) if model_type == \"classifier\" else None\n",
    "test_data_proc = pd.concat([X_test_proc, y_test], axis=1) if model_type == \"classifier\" else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeb53f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dtale_eda(dataset)\n",
    "#df.main_url()\n",
    "with open(\"temp.log\", \"w\") as f:\n",
    "    with redirect_stdout(f):\n",
    "        df.main_url()\n",
    "with open(\"temp.log\") as f:\n",
    "    href = f.readlines()\n",
    "href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6041a657",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoviz_eda2(dataset.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad21e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ydata_profiling_eda2(dataset.sample(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbef252",
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'classifier':\n",
    "    target_feature = target[0]\n",
    "    drop_cols = ['id', 'member_id', 'issue_d', 'title', 'zip_code', 'addr_state', 'last_pymnt_d',\n",
    "             'next_pymnt_d', 'last_credit_pull_d', 'tot_coll_amt', 'tot_cur_bal', 'total_rev_hi_lim']\n",
    "    num_cols = list(set(dataset.select_dtypes(include = ['int64', 'float64']).columns.tolist()) - set(drop_cols) - set(target_feature))\n",
    "    cat_cols = list(set(dataset.select_dtypes(exclude = ['int64', 'float64']).columns.tolist()) - set(drop_cols) - set(target_feature))\n",
    "    rai_insights, cohort_list = xrai_features(list(model_selected.values())[0], train_data.drop(drop_cols, axis = 1),\n",
    "                                              test_data.drop(drop_cols, axis = 1), target_feature, categorical_features = cat_cols\n",
    "                                             )\n",
    "    ResponsibleAIDashboard(rai_insights, cohort_list=cohort_list)\n",
    "else:\n",
    "    pipe = model['DT'][:-1]\n",
    "    features = pipe.get_feature_names_out()\n",
    "    pipe.fit(X_train)\n",
    "    X_test_proc = pd.DataFrame(pipe.transform(X_test), columns=features)\n",
    "    predictions = model['DT'][-1].predict(X_test_proc)\n",
    "    ErrorAnalysisDashboard(dataset=X_test_proc, true_y=y_test, features=features, pred_y=predictions, model_task='regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a19595e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-05 11:20:19,363 - INFO     - Executing shutdown due to inactivity...\n",
      "2023-10-05 11:20:35,870 - INFO     - Executing shutdown...\n",
      "2023-10-05 11:20:35,876 - INFO     - Not running with the Werkzeug Server, exiting by searching gc for BaseWSGIServer\n"
     ]
    }
   ],
   "source": [
    "if reg:\n",
    "    try:\n",
    "        ExplainerDashboard(explainer, [\n",
    "                                    EDATab(explainer, href),\n",
    "                                    FairnessTab(explainer, model_selected, X_test, y_test, X_train, y_train, test_data, train_data, test_data_proc, train_data_proc, target_feature, model_type),\n",
    "                                    LocalExpTab(explainer, model_selected, X_train, y_train, X_test,cont, cat, model_type, target_feature, pipe),\n",
    "                                    GlobalExpTab(explainer, exp, model_selected, X_train, pipe, cat, model_type, variable_groups, features),\n",
    "                                    StabilityTab(explainer, X_train, y_train, X_test, y_test, cont, pipe, model_selected, train_data, test_data, target_feature, model_type),\n",
    "                                    StabilityTestTab(explainer, model_selected, train_data, test_data, target_feature, model_type),\n",
    "                                    RobustnessTab(explainer, model_selected, X_train_proc, y_train, X_test_proc, y_test, model_type),\n",
    "                                    UncertaintyTab(explainer, model_selected, X_train_proc, y_train, X_test, y_test, model_type),\n",
    "                                    ], bootstrap = dbc.themes.FLATLY, hide_header = True).run()\n",
    "    except:\n",
    "        print('Hello!')\n",
    "elif not reg:\n",
    "    try:\n",
    "        ExplainerDashboard(explainer, [\n",
    "                                EDATab(explainer, href),\n",
    "                                FairnessTab(explainer, model_selected, X_test, y_test, X_train, y_train, test_data, train_data, test_data_proc, train_data_proc, target_feature, model_type),\n",
    "                                LocalExpTab(explainer, model_selected, X_train, y_train, X_test,cont, cat, model_type, target_feature, preprocessor),\n",
    "                                GlobalExpTab(explainer, exp, model_selected, X_train, preprocessor, cat, model_type, variable_groups, features),\n",
    "                                StabilityTab(explainer, X_train, y_train, X_test, y_test, cont, preprocessor, model_selected, train_data, test_data, target_feature, model_type),\n",
    "                                StabilityTestTab(explainer, model_selected, train_data, test_data, target_feature, model_type),\n",
    "                                RobustnessTab(explainer, model_selected, X_train_proc, y_train, X_test_proc, y_test, model_type),\n",
    "                                UncertaintyTab(explainer, model_selected, X_train_proc, y_train, X_test, y_test, model_type),\n",
    "                                ], bootstrap = dbc.themes.FLATLY, hide_header = True).run()\n",
    "    except:\n",
    "        print('Hello!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea0ec6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XRAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
